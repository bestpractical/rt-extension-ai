% my $abort = 1;  # Declare and set $abort
% my @suggestions;  # Declare @suggestions
% $r->content_type('application/json; charset=utf-8') if $abort;
% $m->abort if $abort;
<% JSON( \@suggestions ) |n %>
<%ARGS>
$rawText => ''  # Corresponds to input text from the user
$callType => '' # Corresponds to the type of call (aisuggestion, adjustTone, translate, autocomplete etc.)
$transFrom => ''
$transTo => ''
</%ARGS>

<%INIT>
use RT;
use RT::Config;
use HTTP::Request;
use LWP::UserAgent;
use JSON;

RT->LoadConfig;
my $config = RT->Config;

my $openai_api_key = $config->Get('OpenAI_ApiKey');
my $api_url = $config->Get('OpenAI_ApiUrl');
my $adjustTone = $config->Get('AdjustTone');
my $aisuggestion = $config->Get('AiSuggestion');
my $translate = $config->Get('Translate');
my $autocomplete = $config->Get('Autocomplete');

my $GeneralAIModel = $config->Get('GeneralAIModel')->{modelDetails};
my $AutoCompleteModel = $config->Get('AutoCompleteModel')->{modelDetails};
my ($modelName, $temperature, $maxToken, $stream, $prompt);

RT::Logger->info("Received rawText: $rawText, callType: $callType");

# Abort if OpenAI API key is missing
$m->abort("Missing OpenAI API key") unless $openai_api_key && $openai_api_key ne $api_url;

# Retrieve parameters from the request (from the template ARGS)
my $input_text = $rawText || '';  # Input text from the user
my $option_type = $callType || 'aisuggestion';  # Type of suggestion (aisuggestion, adjustTone, etc.)

# Define prompt templates for different option types
my %ai_prompt = (
    adjustTone   => $adjustTone,
    aisuggestion => $aisuggestion,
    translate    => $translate,
    autocomplete => $autocomplete
);

# Check the option type and construct the prompt
my $prefix = 'Give me response for the prompt as HTML with only paragraph tag : ';

if (defined $transFrom && $transFrom ne '' && defined $transTo && $transTo ne '') {
    $ai_prompt{translate} .= $transFrom . ' to ' . $transTo;
} else {
    $ai_prompt{translate} .= 'English' . ' to ' . 'Spanish';
}

if ($option_type eq 'autocomplete') {
    $prompt = $ai_prompt{$option_type} || $ai_prompt{'aisuggestion'};
    $modelName = $AutoCompleteModel->{modelName};
    $temperature = $AutoCompleteModel->{temperature};
    $maxToken = $AutoCompleteModel->{maxToken};
    $stream = $AutoCompleteModel->{stream};
} else {
    $prompt = $prefix . ($ai_prompt{$option_type} || $ai_prompt{'aisuggestion'});
    $modelName = $GeneralAIModel->{modelName};
    $temperature = $GeneralAIModel->{temperature};
    $maxToken = $GeneralAIModel->{maxToken};
    $stream = $GeneralAIModel->{stream};
}
RT::Logger->info("Using AI prompt: $prompt");
RT::Logger->info(" ******* Using AI variables: $prompt, $modelName, $temperature, $maxToken");

# Prepare the OpenAI API request
my $ua = LWP::UserAgent->new;
my $request = HTTP::Request->new(
    'POST',
    $api_url,
    [
        'Content-Type'  => 'application/json',
        'Authorization' => "Bearer $openai_api_key"
    ],
    encode_json({
        model => $modelName,  # Model version
        messages => [
            { role => 'system', content => $prompt },
            { role => 'user', content => $input_text }
        ],
        max_tokens => $maxToken,  # Set max tokens
        temperature => $temperature  # Temperature for creativity control
    })
);

# Send the request to OpenAI API and handle the response
my $response = $ua->request($request);
my $suggestion = '';

if ($response->is_success) {
    my $content = eval { decode_json($response->content) };  # Safely decode JSON
    if ($@) {
        $m->abort("Failed to decode JSON: $@");
    }
    $suggestion = $content->{choices}[0]{message}{content} || 'No suggestion available';
} else {
    $m->abort("Error calling OpenAI API: " . $response->status_line);
}

# Return the suggestion as JSON
print encode_json({ suggestion => $suggestion });
</%INIT>